# Week Four Journal

 
 
 I really meant to get all this done sooner but I didn't. No excuses and I'm working on finishing the rest of the material by Thursday.
 
 
 ## Readings
 
 These articles were very intersting and made me think more about what Digital History is. For example,  the ["Digital History and Argument" White Paper](https://rrchnm.org/argument-white-paper/) shows how even though Digital Histoy is a "new" approach to studying History, it is still rooted in the previous studies of History. This makes me realize that Digital History isn't really a new approach to History, but an evolution. It is taking new tools and applying some of the same approaches to making historical arguments. This ppaer also details how the more traditional History Scholars and the "new" Digital Historians can work together to further History which is important I think since the more everyone works together, the better the work will be, the more people they can reach.
 
 
 
 Reading the [Big Data for Dead People](https://historyonics.blogspot.com/2013/12/big-data-for-dead-people-digital.html) blog raised some key points I think in how we approach Digital History. When he speaks about realizing how Big Data is often viewed, and how it can alter our view of the results (usually raw/big data results seem more "scientific" and "true" to people and how chasing this trend could result in a more positivist view of history was eye-opening. I knew that there were always some biases with raw data (no data is really raw anyways) but seeing it spelled out like this made sense to me. He made sure to mention that textual analysis, as well as geospatial, etc. are all part of Historical study, but that when considering Big Data vs Small Data, it is important to know the limitations of both and to go into projects with that open mind to ensure you will be able to get the most out of your analysis. This is important for students to learn since sometimes they can get married to one method, and solely focus on that while not realizing the shortcomings. If done right, these Big Data analyses can work very well with textual analysis to provide indiviudal stories. His example of the Trials was very cool to see the micro and macro level, and goes to show how digital history can evolve and reach more people.
 
 
 
 [Confabulation in the Humanities](https://matthewlincoln.net/2015/03/21/confabulation-in-the-humanities.html) really made me think about how we go about History and why it can sometimes be seen as "boring" to others. It raised the point that despite doing new research leading to new findings, they tend to be rationalized away as things we already knew, or already could have guessed. It is important that we actually look at the data to prove things, instead of relying on guesswork and theories. Actually investigating the trends and then using our hypotheses to explain them is still new work that needs to be done, even if it isn't the "sexy" digital humanities work. The same could go for digitization or other digital fields such as metadata that tend to get overlooked for the big fancy graphics that are made.
 
 
 ## Excel and R
 
 I have some history of playing around in excel, both just for fun and for work so I enjoyed learning how I can fit my excel skills into a historical context. This will definitely be useful for further use and examination of historical databases.
 
 
 
 
 
 
 ## Voyant
 

Voyant is a personal favourite tool for use in the Digital Humanities. I've explored it in depth in a previous course so I enjoyed playing around with it in a different, more historical context. Some of the tools provide basic work which tells a simple story, but there are also more indepth tools that allow for a more detailed analysis.

Due to me mismanaging my time I did not create my own corpus to analyze as I wanted to prioritze getting other things done.




## AntConc

Despite some initial problems setting AntConc up, once I was able to load my data it was a very useful tool. It can do a lot of detailed textual analysis which can be very useful.




## Topic Models

Despite some initial problems setting the Topic Modelling tool up, I was able to figure things out and look at some really interesting findings. However I did not spend much time on this as I wanted to get other things done and I enjoyed my time in R more so I spent more time there.

I actually have been really enjoying learning some of the basics in R. I know and see a lot of people talking about it since I follow a lot of people into Hockey Analytics on Twitter, so I always see them talking about ggplot, tidyverse, etc. And it has been really interesting to  actually start to see and understand some of the basics. I can see how and why R can be a useful and powerful tool for analyzing data.

The code I learned to make the topic model here can definitely be tweaked to run on other data, which is something I am going to remember going forward so I can use R and learn more about it as I have enjoyed it and want to use it more.




## Weekly Reflection

I thought the readings this week did a really good job at showing how digital arguments are made, and received in the current scholarly environment. Digital History is sometimes touted as "new" and "groundshattering" or other similar terms to try and get attention focused on it. In my mind though, it is an evolution of previous historical work using new tools to explore data that wasn't possible before. If more people understood this and tried to learn some of the basic underlying aspects, then I think digital history could be more widely accepted by traditional historians. 

In my experience, learning history is often done through traditional close reads of primary/secondary sources. Then based on those we attempt to analyze and discern their meaning. Sifting through large datasets of digitized newspaper recordings isn't usually focused on. The few times I used digitized newspapers, it was for very specific focuses. Although maybe the use of these digitized nespapers do show some ways in which digital history is already impacting aspects of traditional historical scholarship. But being able to parse these large set of databases to highlight findings which can then be further explored should be something that everyone agrees on and finds useful. Having close reads and distant reads of data allow for everything to be understood in a more clear manner. Having both perspectives will allow for better historical arguments and a more nuanced view of history. 

I don't think having digital works should change how we argue historical points, we are simply using our knowledge, whether it be from datasets, primary sources, etc. and using it to draw conclusions. I don't think that a priori knowledge is required to develop good historical arguments. Sometimes a priori knowledge may actually hinder the potential to identify good arguments and present them to readers. Someone with no preconceived biases about what the data is going to reveal should be able to create a more honest and truthful explanation of the findings than someone who went into the analysis with an expectation of what they were going to find. However in very complex parts I can see how a priori knowledge would be useful to identify trends or pick out specific findings that would be useful to readers/viewers. So maybe it is a case where both a priori knowledge helps and hinders, and that a useful mix of each can lead to better projects.
